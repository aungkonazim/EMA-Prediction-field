{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score,r2_score,classification_report,roc_auc_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV,StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "def svar(X):\n",
    "    n = float(len(X))\n",
    "    svar=(sum([(x-np.mean(X))**2 for x in X]) / n)* n/(n-1.)\n",
    "    return svar\n",
    "\n",
    "def CronbachAlpha(itemscores):\n",
    "    itemvars = [svar(item) for item in itemscores]\n",
    "    tscores = [0] * len(itemscores[0])\n",
    "    for item in itemscores:\n",
    "        for i in range(len(item)):\n",
    "            tscores[i]+= item[i]\n",
    "    nitems = len(itemscores)\n",
    "    Calpha=nitems/(nitems-1.) * (1-sum(itemvars)/ svar(tscores))\n",
    "    return Calpha\n",
    "\n",
    "from scipy.stats import iqr,skew,kurtosis,pearsonr\n",
    "from scipy.stats import variation,moment\n",
    "\n",
    "def get_features1(x):\n",
    "    temp = []\n",
    "    temp.append(x[-1])\n",
    "    temp.append(x[0])\n",
    "    temp.append(x[len(x)//2])\n",
    "    temp.append(iqr(x))\n",
    "    temp.append(skew(x))\n",
    "    temp.append(kurtosis(x))\n",
    "    temp.append(variation(x))\n",
    "    temp.append(iqr(x[:len(x)//2]))\n",
    "    temp.append(skew(x[:len(x)//2]))\n",
    "    temp.append(kurtosis(x[:len(x)//2]))\n",
    "    temp.append(variation(x[:len(x)//2]))\n",
    "    temp.append(iqr(x[len(x)//2:]))\n",
    "    temp.append(skew(x[len(x)//2:]))\n",
    "    temp.append(kurtosis(x[len(x)//2:]))\n",
    "    temp.append(variation(x[len(x)//2:]))\n",
    "    return np.array(temp)\n",
    "\n",
    "# def get_features()\n",
    "\n",
    "def get_features(temp,user):\n",
    "    if temp.shape[0]<10:\n",
    "        return -1,-1,-1,-1,-1\n",
    "    if temp['time'].values[-1]-temp['time'].values[0]>1000:\n",
    "        return -1,-1,-1,-1,-1\n",
    "    if np.isnan(temp['score'].values[-1]):\n",
    "        return -1,-1,-1,-1,-1\n",
    "    a = temp['stress_likelihood'].values\n",
    "    b = temp['all_scores'].values[-1]\n",
    "    c = user\n",
    "    hour = datetime.fromtimestamp(temp['time'].values[0]).hour\n",
    "    if hour<8:\n",
    "        d = 0\n",
    "    elif hour>8 and hour < 16:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = 2\n",
    "    e = user+temp['day'].values[-1]\n",
    "    return a,b,c,d,e\n",
    "\n",
    "def get_features2(temp,user):\n",
    "    if temp.shape[0]<10:\n",
    "        return -1,-1,-1,-1,-1\n",
    "    if temp['time'].values[-1]-temp['time'].values[0]>1000:\n",
    "        return -1,-1,-1,-1,-1\n",
    "    g = temp['score'].values\n",
    "    if len(g[~np.isnan(g)])>0:\n",
    "        return -1,-1,-1,-1,-1\n",
    "#     if np.isnan(temp['score'].values[-1]):\n",
    "#         return -1,-1,-1,-1,-1\n",
    "    a = temp['stress_likelihood'].values\n",
    "    b = temp['all_scores'].values[-1]\n",
    "    c = user\n",
    "    hour = datetime.fromtimestamp(temp['time'].values[0]).hour\n",
    "    if hour<8:\n",
    "        d = 0\n",
    "    elif hour>8 and hour < 16:\n",
    "        d = 1\n",
    "    else:\n",
    "        d = 2\n",
    "    e = user+temp['day'].values[-1]\n",
    "    return a,b,c,d,e\n",
    "\n",
    "def get_user_data(user_data,user):\n",
    "    X_date = []\n",
    "    X = []\n",
    "    y = []\n",
    "    groups = []\n",
    "    days = []\n",
    "    if len(np.unique(user_data.dropna()['day'].values))<4:\n",
    "        return [],[],[],[],[]\n",
    "    user_data = user_data.sort_values('localtime').reset_index(drop=True)\n",
    "    count = 0\n",
    "    columns=['window', 'localtime', 'day', 'stress_likelihood', 'imputed',\n",
    "       'likelihood_mean', 'all_scores', 'score', 'label', 'version', 'user',\n",
    "       'time']\n",
    "    count = 0\n",
    "    data = Parallel(n_jobs=20,verbose=1)(delayed(get_features)(user_data.loc[i:i+10],user) for i,row in user_data.iterrows()\n",
    "                                        if not np.isnan(user_data.loc[i:i+10]['score'].values[-1]))\n",
    "    data1 = Parallel(n_jobs=20,verbose=1)(delayed(get_features2)(user_data.loc[i:i+10],user) for i,row in user_data.iterrows()\n",
    "                                        if i%10==0)\n",
    "    \n",
    "    data = data+data1\n",
    "    for a in data:\n",
    "        if not isinstance(a[2], str):\n",
    "            continue\n",
    "        X.append(a[0])\n",
    "        y.append(a[1])\n",
    "        groups.append(a[2])\n",
    "        X_date.append(a[3])\n",
    "        days.append(a[4])\n",
    "    print(len(X))\n",
    "    return X,y,groups,X_date,days\n",
    "\n",
    "\n",
    "def get_data(all_stress):\n",
    "    X_date,X,y,groups,days = [],[],[],[],[]\n",
    "    final = [get_user_data(all_stress[all_stress.user.isin([user])],user) \n",
    "                                          for user in np.unique(all_stress['user'].values)]\n",
    "    for a in final:\n",
    "        X.extend(a[0])\n",
    "        y.extend(a[1])\n",
    "        groups.extend(a[2])\n",
    "        X_date.extend(a[3])\n",
    "        days.extend(a[4])\n",
    "    return X,y,groups,X_date,days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "all_stress_left = pickle.load(open('../data/stress_ema_md2k_aa_rice_left_ppg.p','rb'))\n",
    "# all_stress_left = all_stress_left[all_stress_left.imputed.isin([0])]\n",
    "all_stress_right = pickle.load(open('../data/stress_ema_md2k_aa_rice_right1_ppg.p','rb'))\n",
    "# all_stress_right = all_stress_right[all_stress_right.imputed.isin([0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X2,y2,groups2,X_date2,days2 = get_data(all_stress_left)\n",
    "X3,y3,groups3,X_date3,days3 = get_data(all_stress_right)\n",
    "Xf,yf,groupsf,X_datef,daysf = X2+X3,y2+y3,groups2+groups3,X_date2+X_date3,days2+days3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([Xf,yf,groupsf,X_datef,daysf],open('../data/semi_supervised_no_imputation.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azim/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done 166 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=30)]: Done 2880 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=30)]: Done 24320 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=30)]: Done 53120 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=30)]: Done 88320 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=30)]: Done 129920 tasks      | elapsed:   14.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174735, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done 174735 out of 174735 | elapsed:   19.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "Xf,yf,groupsf,X_datef,daysf = pickle.load(open('../data/semi_supervised_no_imputation.p','rb'))\n",
    "X,y1,groups1,X_date_final = np.array(Xf),np.array(yf),np.array(groupsf),OneHotEncoder().fit_transform(np.array(X_datef).reshape(-1,1))\n",
    "Xfeatures = np.array(Parallel(n_jobs=30,verbose=1)(delayed(get_features1)(x) for x in Xf))\n",
    "print(Xfeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1579, 15) (1559, 15) (20, 15) (1579,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    2.0s remaining:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(2950, 15) (2883, 15) (67, 15) (2950,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    2.4s remaining:    1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(2163, 15) (2104, 15) (59, 15) (2163,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.8s remaining:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(1518, 15) (1494, 15) (24, 15) (1518,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.4s remaining:    1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       1.         0.5        0.66666667]\n",
      "(1201, 15) (1183, 15) (18, 15) (1201,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.2s remaining:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.625 1.    0.25  0.4  ]\n",
      "(1975, 15) (1932, 15) (43, 15) (1975,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.6s remaining:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(1817, 15) (1794, 15) (23, 15) (1817,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.5s remaining:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(3541, 15) (3459, 15) (82, 15) (3541,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    2.7s remaining:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(2281, 15) (2266, 15) (15, 15) (2281,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    1.9s remaining:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.  0.  0. ]\n",
      "(3289, 15) (3239, 15) (50, 15) (3289,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  40 out of  40 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  22 out of  40 | elapsed:    2.5s remaining:    2.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7393f4886ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m'class_weight'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     })\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_performance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparamGrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split,ParameterGrid\n",
    "from frameworks.SelfLearning import SelfLearningModel\n",
    "from frameworks.CPLELearning import CPLELearningModel\n",
    "all_y = []\n",
    "all_y_pred = []\n",
    "all_groups = []\n",
    "def get_labels(y):\n",
    "    temp = np.array([np.mean(a) for a in y])\n",
    "    temp_mean = np.mean(temp)\n",
    "    index2 = np.where(temp>temp_mean)[0]\n",
    "    index1 = np.where(temp<=temp_mean)[0]\n",
    "    temp[index2] = 1\n",
    "    temp[index1] = 0\n",
    "    labels = temp\n",
    "    labels = np.int64(np.array(labels))\n",
    "    return labels\n",
    "def get_model_performance(X_train,y_train,X_test,y_test,params):\n",
    "    clf = LogisticRegression(**params)\n",
    "#     clf = SelfLearningModel(clf)\n",
    "    clf = CPLELearningModel(clf)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test[y_test>-1])\n",
    "    y_test = y_test[y_test>-1]\n",
    "    print(np.array([f1_score(y_test,y_pred),roc_auc_score(y_test,y_pred)]))\n",
    "    return np.array([roc_auc_score(y_test,y_pred),\n",
    "                     precision_score(y_test,y_pred),\n",
    "                     recall_score(y_test,y_pred),\n",
    "                     f1_score(y_test,y_pred)])\n",
    "    \n",
    "all_results = []\n",
    "for user in np.unique(groups1):\n",
    "    index = np.where(groups1==user)[0]\n",
    "    X1,y,groups = Xfeatures[index],y1[index],groups1[index]\n",
    "    index_not_nan = y!=None \n",
    "    X_nn,y_nn,groups_nn = X1[index_not_nan],y[index_not_nan],groups[index_not_nan]\n",
    "    X_n,y_n,groups_n = X1[~index_not_nan],y[~index_not_nan],groups[~index_not_nan]\n",
    "    y_nn = np.array(get_labels(y_nn))\n",
    "    if len(np.unique(y_nn))<2:\n",
    "        continue\n",
    "    if len(y_nn[y_nn==1])<3:\n",
    "        continue\n",
    "    if len(y_nn[y_nn==0])<3:\n",
    "        continue\n",
    "    y_n = [-1]*len(y_n)\n",
    "    X1 = np.concatenate([X_nn,X_n],axis=0)\n",
    "    labels = np.array(list(y_nn)+y_n)\n",
    "    print(X1.shape,X_n.shape,X_nn.shape,labels.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, labels, test_size=0.4, random_state=4,stratify=labels)\n",
    "    paramGrid = ParameterGrid({\n",
    "            'C': np.logspace(-3,3,10),\n",
    "            'class_weight':[{0:1,1:4/2},{0:1,1:3/2},{0:1,1:5/2},{0:1,1:1}]\n",
    "    })\n",
    "    result = np.array(Parallel(n_jobs=30,verbose=1)(delayed(get_model_performance)(X_train,y_train,X_test,y_test,params) for params in paramGrid))\n",
    "    result = result[result[:,0]>=.5]\n",
    "    all_results.append(result[np.argmax(result[:,-1])])\n",
    "    print(result[np.argmax(result[:,1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = np.array(all_results)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.boxplot(all_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = all_results[all_results[:,0].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "roc = all_results[:,0]\n",
    "precision = all_results[:,1]\n",
    "recall = all_results[:,2]\n",
    "f1 = all_results[:,3]\n",
    "x = np.array([i*2 for i in range(len(roc))])\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(x,roc,1)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(x,precision,1)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(x,recall,1)\n",
    "plt.show()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(x,f1,.5)\n",
    "plt.show()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frameworks.CPLELearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
